{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LLM1 = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/LLM_processed(1).csv')\n",
    "df_LLM2 = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/LLM_processed(2).csv')\n",
    "df_LLM31 = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/LLM_processed(3.1).csv')\n",
    "df_LLM32 = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/LLM_processed(3.2).csv')\n",
    "df_LLM4 = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/LLM_processed(4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4572, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LLM1.head() \n",
    "df_LLM2.head() \n",
    "#df_LLM31.shape \n",
    "df_LLM32.shape #dataframe is too small just 4116 instead of 4572!!\n",
    "#df_LLM4.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(Dataframe: pd.DataFrame, tolerance: float = 1):\n",
    "    \"\"\"1. Delets all row whitout Rf value or Rf value over 1.0 and without solvent information.\n",
    "       2. Converts percentage of solvents in a Dataframe from str to float and check if they add up to 100, else drop them.\n",
    "       3. Strips productSMILES str to a usable SMILES str.\n",
    "\n",
    "    Args: \n",
    "        Dataframe (_type_): Dataframe containing the processed data from the get_value function.\n",
    "        Dataframe needs to have following columns: 'productSmiles,' 'Rf', 'Percent_A', 'Percent_B'\n",
    "        tolerance (_type_): float, default = 1, tolerance for the sum of the percentages of the solvents (default is 100% +- 1%)\n",
    "\n",
    "    \"\"\"\n",
    "    size_pre_cleaning = len(Dataframe)  # get the size of the dataframe\n",
    "    # Drop rows without Rf values\n",
    "    Dataframe.dropna(subset=['Rf'], inplace = True) \n",
    "    size_after_nan = len(Dataframe)  # get the size of the dataframe after dropping rows with NaN values\n",
    "    print(f\"Number of rows dropped due to NaN values in Rf: {size_pre_cleaning - size_after_nan}, {round((size_pre_cleaning - size_after_nan) / size_pre_cleaning * 100, 2)}%\")\n",
    "\n",
    "    # Convert Rf value to float\n",
    "    Dataframe['Rf'] = Dataframe['Rf'].astype(float)\n",
    "    \n",
    "    #finds indicies with Rf values over 1.0\n",
    "    indices_false_Rf = Dataframe[Dataframe[\"Rf\"] > 1].index \n",
    "    Dataframe.drop(indices_false_Rf,inplace = True) #drops rows with false Rf values\n",
    "    size_after_false_Rf = len(Dataframe)  # get the size of the dataframe after dropping rows with Rf values over 1.0\n",
    "    print(f\"Number of rows dropped due to Rf values over 1.0: {len(indices_false_Rf)}, {round(len(indices_false_Rf) / size_pre_cleaning * 100, 2)}%\")\n",
    "    \n",
    "    #check if at least one solvent (either solvent A or solvent B) is given (so check that solvent A and solvent B are not None)\n",
    "    Dataframe = Dataframe[Dataframe['Solvent_A'].notnull() & Dataframe['Solvent_B'].notnull()].copy()\n",
    "    size_after_solvent_drop = len(Dataframe)  # get the size of the dataframe after dropping rows without solvent information\n",
    "    print(f\"Number of rows dropped due to missing solvent information: {size_after_false_Rf - size_after_solvent_drop}, {round((size_after_false_Rf - size_after_solvent_drop) / size_pre_cleaning * 100, 2)}%\")\n",
    "\n",
    "    #convert 'None' entry to 0\n",
    "    Dataframe.loc[:, 'Percent_A'] = Dataframe['Percent_A'].apply(lambda x: 0 if x is None else x)\n",
    "    \n",
    "    #convert 'None' entry to 0\n",
    "    Dataframe.loc[:, 'Percent_B'] = Dataframe['Percent_B'].apply(lambda x: 0 if x is None else x)\n",
    "    \n",
    "    # convert Percentage to float\n",
    "    Dataframe.loc[:, 'Percent_A'] = Dataframe['Percent_A'].apply(lambda x: float(x)) \n",
    "    \n",
    "    #convert Percantage to float\n",
    "    Dataframe.loc[:, 'Percent_B'] = Dataframe['Percent_B'].apply(lambda x: float(x)) \n",
    "    \n",
    "    # Drop rows where 'additive_C' is not None\n",
    "    Dataframe = Dataframe[Dataframe['Additive_C'].isnull()].copy()\n",
    "    size_after_additive_drop = len(Dataframe)  # get the size of the dataframe after dropping rows with additive C\n",
    "    print(f\"Number of rows dropped due to additive C: {size_after_solvent_drop - size_after_additive_drop}, {round((size_after_solvent_drop - size_after_additive_drop) / size_pre_cleaning * 100, 2)}%\")\n",
    "\n",
    "    # remove [' and '] from the productSimles\n",
    "    Dataframe.loc[:, 'productSmiles'] = Dataframe['productSmiles'].apply(lambda x: x[2:-2]) \n",
    "    \n",
    "    # check if the sum of the percentages is 100, this at the same time kicks out entries with additives C (+ consider limitations of floating-point arithmetic)\n",
    "    Dataframe.loc[:, 'sum'] = Dataframe['Percent_A'] + Dataframe['Percent_B']\n",
    "    Dataframe = Dataframe[(Dataframe['sum'] >= 100 - tolerance) & (Dataframe['sum'] <= 100 + tolerance)].copy()\n",
    "    size_after_percentage_check = len(Dataframe)  # get the size of the dataframe after dropping rows with wrong percentages\n",
    "    print(f\"Number of rows dropped due to wrong percentages: {size_after_additive_drop - size_after_percentage_check}, {round((size_after_additive_drop - size_after_percentage_check) / size_pre_cleaning * 100, 2)}%\")\n",
    "\n",
    "    Dataframe.reset_index(drop=True, inplace=True) # sets the index new from 1 to end\n",
    "\n",
    "    size_post_cleaning = Dataframe.shape[0]  # get the size of the dataframe after cleaning\n",
    "    print(f\"Size of the dataframe before cleaning: {size_pre_cleaning}\")\n",
    "    print(f\"Size of the dataframe after cleaning: {size_post_cleaning}\")\n",
    "    print(f\"Number of rows dropped: {size_pre_cleaning - size_post_cleaning}\")\n",
    "    print(f\"Percentage of rows dropped: {(size_pre_cleaning - size_post_cleaning) / size_pre_cleaning * 100}%\")\n",
    "    return Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting all the Datarfames to one and make a csv file\n",
    "\n",
    "df_LLM = pd.concat([df_LLM1, df_LLM2, df_LLM31, df_LLM32, df_LLM4], axis=0, ignore_index=True)\n",
    "\n",
    "#needs to be repeated with df_LLM32 with original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphText</th>\n",
       "      <th>reactionSmiles</th>\n",
       "      <th>productSmiles</th>\n",
       "      <th>title</th>\n",
       "      <th>Rf</th>\n",
       "      <th>Solvent_A</th>\n",
       "      <th>Solvent_B</th>\n",
       "      <th>Percent_A</th>\n",
       "      <th>Percent_B</th>\n",
       "      <th>Additive_C</th>\n",
       "      <th>Percent_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A] Synthesis of 1-benzyl-piperidin-4-ylidene)...</td>\n",
       "      <td>C(CC([O-])=O)#N.[CH2:7]([N:14]1[CH2:19][CH2:18...</td>\n",
       "      <td>['C(C1=CC=CC=C1)N1CCC(CC1)=C(C(=O)OCC)C#N']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A solution of (S)-(+)-3-hydroxytetrahydrofuran...</td>\n",
       "      <td>O[C@H]1CCOC1.CC([O-])(C)C.[K+].[CH3:13][O:14][...</td>\n",
       "      <td>['COC(=O)C=1SC=CC1']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>dichloromethane</td>\n",
       "      <td>ethyl acetate</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solution of 4-{[(phenylmethoxy)carbonylamino...</td>\n",
       "      <td>[C:1]1([CH2:7][O:8][C:9]([NH:11][CH2:12][C:13]...</td>\n",
       "      <td>['CON(C(=O)C1=CC=C(C=C1)CNC(=O)OCC1=CC=CC=C1)C']</td>\n",
       "      <td>Preparation of N-methoxy-N-methyl(4-{[(phenylm...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>pentane</td>\n",
       "      <td>EtOAc</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Putative nitrilase up-mutants were assayed in ...</td>\n",
       "      <td>[CH3:1][C:2]1(C)S[C@@H]2[C@H](NC([C@H](N)C3C=C...</td>\n",
       "      <td>['O[C@@H](CC(=O)O)CC#N']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>EtOAc</td>\n",
       "      <td>Hexanes</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0 g N6-Benzoyl-5′-O-tert-butyldimethylsilyl-...</td>\n",
       "      <td>[C:1]([NH:9][C:10]1[C:11]2[N:12]=[CH:13][N:14]...</td>\n",
       "      <td>['C(C1=CC=CC=C1)(=O)NC=1C=2N=CN([C@H]3C[C@H](O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraphText  \\\n",
       "0  [A] Synthesis of 1-benzyl-piperidin-4-ylidene)...   \n",
       "1  A solution of (S)-(+)-3-hydroxytetrahydrofuran...   \n",
       "2  A solution of 4-{[(phenylmethoxy)carbonylamino...   \n",
       "3  Putative nitrilase up-mutants were assayed in ...   \n",
       "4  3.0 g N6-Benzoyl-5′-O-tert-butyldimethylsilyl-...   \n",
       "\n",
       "                                      reactionSmiles  \\\n",
       "0  C(CC([O-])=O)#N.[CH2:7]([N:14]1[CH2:19][CH2:18...   \n",
       "1  O[C@H]1CCOC1.CC([O-])(C)C.[K+].[CH3:13][O:14][...   \n",
       "2  [C:1]1([CH2:7][O:8][C:9]([NH:11][CH2:12][C:13]...   \n",
       "3  [CH3:1][C:2]1(C)S[C@@H]2[C@H](NC([C@H](N)C3C=C...   \n",
       "4  [C:1]([NH:9][C:10]1[C:11]2[N:12]=[CH:13][N:14]...   \n",
       "\n",
       "                                       productSmiles  \\\n",
       "0        ['C(C1=CC=CC=C1)N1CCC(CC1)=C(C(=O)OCC)C#N']   \n",
       "1                               ['COC(=O)C=1SC=CC1']   \n",
       "2   ['CON(C(=O)C1=CC=C(C=C1)CNC(=O)OCC1=CC=CC=C1)C']   \n",
       "3                           ['O[C@@H](CC(=O)O)CC#N']   \n",
       "4  ['C(C1=CC=CC=C1)(=O)NC=1C=2N=CN([C@H]3C[C@H](O...   \n",
       "\n",
       "                                               title    Rf        Solvent_A  \\\n",
       "0                                                NaN  0.53              NaN   \n",
       "1                                                NaN  0.30  dichloromethane   \n",
       "2  Preparation of N-methoxy-N-methyl(4-{[(phenylm...  0.30          pentane   \n",
       "3                                                NaN  0.50            EtOAc   \n",
       "4                                                NaN  0.60              NaN   \n",
       "\n",
       "       Solvent_B  Percent_A  Percent_B Additive_C  Percent_C  \n",
       "0            NaN        NaN        NaN        NaN        NaN  \n",
       "1  ethyl acetate      100.0       20.0        NaN        1.0  \n",
       "2          EtOAc       50.0       50.0        NaN        NaN  \n",
       "3        Hexanes       50.0       50.0        NaN        NaN  \n",
       "4            NaN        NaN        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LLM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LLM.to_csv(r'/Users/matthiasgalka/git/ppchem_project/data/After_LLM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped due to NaN values in Rf: 12017, 33.27%\n",
      "Number of rows dropped due to Rf values over 1.0: 473, 1.31%\n",
      "Number of rows dropped due to missing solvent information: 3851, 10.66%\n",
      "Number of rows dropped due to additive C: 2582, 7.15%\n",
      "Number of rows dropped due to wrong percentages: 583, 1.61%\n",
      "Size of the dataframe before cleaning: 36123\n",
      "Size of the dataframe after cleaning: 16617\n",
      "Number of rows dropped: 19506\n",
      "Percentage of rows dropped: 53.998837305871604%\n"
     ]
    }
   ],
   "source": [
    "df_LLM_clean = clean_up(df_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_salts(Dataframe: pd.DataFrame):\n",
    "    \"\"\"Removes salts from a Dataframe containing SMILES strings.\n",
    "\n",
    "    Args:   \n",
    "\n",
    "    \"\"\"\n",
    "    size_with_salts = len(Dataframe)  # get the size of the dataframe\n",
    "\n",
    "    indices_false_Rf = Dataframe[Dataframe[\"productSmiles\"].str.contains('\\.')].index \n",
    "    Dataframe.drop(indices_false_Rf,inplace = True)\n",
    "    size_without_salts = len(Dataframe)  # get the size of the dataframe after dropping rows with Rf values over 1.0\n",
    "    print(f\"number of rows dropped due to salts: {size_with_salts - size_without_salts}, {round((size_with_salts - size_without_salts) / size_with_salts * 100, 2)}%\")\n",
    "\n",
    "    return Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows dropped due to salts: 289, 1.74%\n"
     ]
    }
   ],
   "source": [
    "df_no_salt = remove_salts(df_LLM_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try some things to solve the Smiles problem (two product Smiles, Salts, Enatiomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_rows_with_dot(Dataframe: pd.DataFrame):\n",
    "    \n",
    "    ''' Finds all entries with product Smiles which are salts, complexes or Molecuels sperated by a '.' and puts them into a\n",
    "        new Dataframe.\n",
    "\n",
    "    Args: \n",
    "        Datafarme which contains a column called 'productSmiles' with Smiles.\n",
    "    '''\n",
    "    df_salts = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Iteriere über jede Zeile im DataFrame\n",
    "    for index, row in Dataframe.iterrows():\n",
    "        # Überprüfe, ob der Wert in der Spalte \"productSmiles\" einen Punkt enthält\n",
    "        if '.' in row['productSmiles']:\n",
    "            # Füge die Zeile zum DataFrame df_salts hinzu\n",
    "            df_salts = pd.concat([df_salts,pd.DataFrame([row])], ignore_index =False)\n",
    "    \n",
    "    return df_salts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/k5y5cj453pvcsblxlzlzn0340000gn/T/ipykernel_3571/408940893.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_salts = pd.concat([df_salts,pd.DataFrame([row])], ignore_index =False)\n"
     ]
    }
   ],
   "source": [
    "df_salt = find_rows_with_dot(df_LLM_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_smiles(Dataframe: pd.DataFrame, column_name: str):\n",
    "    \"\"\"Function that canonicalizes the SMILES strings in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        Dataframe (pd.DataFrame): Dataframe containing the extracted data from the US patents, \n",
    "                                preprocessed with the get_values, clean_up, and convert_solvents function.\n",
    "                                \n",
    "        column_name (str): name of the column that needs to be canonicalized e.g. productSmiles or Solvent_A_Smiles etc.\n",
    "    \"\"\"\n",
    "    for index, row in Dataframe.iterrows():\n",
    "        try: \n",
    "            smiles_to_canon = row[column_name]\n",
    "            if smiles_to_canon is not None:\n",
    "                p_mol = Chem.MolFromSmiles(smiles_to_canon)\n",
    "                if p_mol is not None:\n",
    "                    smiles_to_canon = Chem.MolToSmiles(p_mol)\n",
    "                    Dataframe.at[index, 'productSmiles'] = smiles_to_canon\n",
    "                else:\n",
    "                    print(f\"Could not canonicalize SMILES for product at index {index}, value is {smiles_to_canon}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error at index {index}, smiles value is {smiles_to_canon}\")\n",
    "        \n",
    "    return Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Strigs (Smiles)\n",
    "\n",
    "S_a_k = \"COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\"\n",
    "a_S_k_a = \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\"\n",
    "a_S_a_k_a = \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\"\n",
    "a_S_a_k_w_a = \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\"\n",
    "S_k_a_w_a_S = \"C(=O)(C(F)(F)F)O', 'O=C(CN1N=C(C2=CC=CC=C12)C(=O)N)N1[C@@H]2C[C@@H]2C[C@H]1C(NC1=NN(C=C1)CC(F)(F)F)=O\"\n",
    "En_ = \"[Si](C)(C)(C(C)(C)C)O[C@H]1C[C@H](C[C@H]([C@@H]1O[Si](C)(C)C(C)(C)C)C)C1=C(C=NC=C1)N', '[Si](C)(C)(C(C)(C)C)O[C@@H]1C[C@@H](C[C@@H]([C@H]1O[Si](C)(C)C(C)(C)C)C)C1=C(C=NC=C1)N\"\n",
    "\n",
    "test_1 = [S_a_k, a_S_k_a, a_S_a_k_a, a_S_a_k_w_a]\n",
    "\n",
    "test_2 = [S_a_k, a_S_k_a, a_S_a_k_a, a_S_a_k_w_a, S_k_a_w_a_S, En_]\n",
    "\n",
    "dic_test_2 = {'productSmiles': test_2}\n",
    "\n",
    "df_test = pd.DataFrame(dic_test_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find a function which removes all komma, apostroph or whitespace from a Smiles. If there is a second Smiles it should seperate them and put it in another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productSmiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C(=O)(C(F)(F)F)O', 'O=C(CN1N=C(C2=CC=CC=C12)C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Si](C)(C)(C(C)(C)C)O[C@H]1C[C@H](C[C@H]([C@@H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       productSmiles\n",
       "0          COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\n",
       "1         'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\n",
       "2        'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\n",
       "3       'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\n",
       "4  C(=O)(C(F)(F)F)O', 'O=C(CN1N=C(C2=CC=CC=C12)C(...\n",
       "5  [Si](C)(C)(C(C)(C)C)O[C@H]1C[C@H](C[C@H]([C@@H..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC\n",
      "[\"COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\"]\n",
      "COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC\n",
      "[\"COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\"]\n",
      "COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC\n",
      "[\"COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\"]\n",
      "COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC\n",
      "[\"COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC',\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC','\", \"'COC1=CC=C(C=C1)[C@@H]1C[C@H](C1)C(=O)OC', '\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "special_characters = [',', ' ', \"'\"]\n",
    "\n",
    "for Smiles in test:\n",
    "\n",
    "    for char in special_characters:\n",
    "        Smiles = Smiles.replace(char, '')\n",
    "    print(Smiles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_Smiles\u001b[39m(productSmiles: \u001b[38;5;28mstr\u001b[39m, Dataframe: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     Smiles_list \u001b[38;5;241m=\u001b[39m productSmiles\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_Smiles(productSmiles: str, Dataframe: pd.DataFrame):\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    Smiles_list = productSmiles.split(\"', '\")\n",
    "\n",
    "    special_characters = [',', ' ', \"'\"]\n",
    "\n",
    "    for Smiles in Smiles_list:\n",
    "\n",
    "        for char in special_characters:\n",
    "            Smiles = Smiles.replace(char, '')\n",
    "    \n",
    "    if len(Smiles_list) == 2:\n",
    "        Dataframe.loc[df['productSmiles'] == productSmiles, 'productSmiles'] = Smiles_list[0]\n",
    "        Dataframe['productSmiles_2'] = Smiles_list[1]\n",
    "    \n",
    "    else:\n",
    "        Dataframe.loc[df['productSmiles'] == productSmiles, 'productSmiles'] = Smiles_list[0]\n",
    "        Dataframe['productSmiles_2'] = np.NaN\n",
    "\n",
    "\n",
    "    return Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LLM.to_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/After_LLM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/matthiasgalka/git/ppchem_project/data/LLM_processed/After_LLM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36579, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppchem_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
